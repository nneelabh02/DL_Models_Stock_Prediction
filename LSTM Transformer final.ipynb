{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5638d14-ccc2-48df-acae-cbb8db5dfd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score, mean_absolute_percentage_error\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import ta\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ===== 0. Set Random Seeds for Reproducibility =====\n",
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ===== 1. Configuration: Define Stocks and Timeframe =====\n",
    "tickers = ['AAPL', 'MSFT', 'GOOGL', 'JPM', 'V', 'JNJ', 'TSLA']\n",
    "stock_to_id = {ticker: i for i, ticker in enumerate(tickers)}\n",
    "id_to_stock = {i: ticker for ticker, i in stock_to_id.items()}\n",
    "\n",
    "start_date = datetime(2015, 1, 1)\n",
    "end_date = datetime.now()\n",
    "seq_len = 60\n",
    "\n",
    "# ===== 2. Data Processing Function for a Single Ticker =====\n",
    "def process_single_ticker(ticker, start, end):\n",
    "    \"\"\"Downloads, cleans, and engineers features for a single stock.\"\"\"\n",
    "    print(f\"\\nProcessing {ticker}...\")\n",
    "    stock_info = yf.Ticker(ticker)\n",
    "    data = stock_info.history(start=start, end=end)\n",
    "    currency = stock_info.info.get('currency', '$')\n",
    "\n",
    "    if data.empty or len(data) < seq_len + 5:\n",
    "        print(f\"No/insufficient data for {ticker} in the given range. Skipping.\")\n",
    "        return None, None, None, None, None, None, None\n",
    "\n",
    "    data = data[['Open', 'High', 'Low', 'Close', 'Volume']].dropna()\n",
    "\n",
    "    # --- Outlier Removal using Z-Score on Daily Returns ---\n",
    "    data['Daily_Return'] = data['Close'].pct_change()\n",
    "    window = 252\n",
    "    rolling_mean = data['Daily_Return'].rolling(window=window, min_periods=1).mean()\n",
    "    rolling_std = data['Daily_Return'].rolling(window=window, min_periods=1).std()\n",
    "    data['Z_Score'] = (data['Daily_Return'] - rolling_mean) / rolling_std\n",
    "    data = data[data['Z_Score'].abs() <= 3.0]\n",
    "    data = data.drop(columns=['Daily_Return', 'Z_Score'])\n",
    "\n",
    "    data['sma_10'] = ta.trend.SMAIndicator(close=data['Close'], window=10).sma_indicator()\n",
    "    data['ema_10'] = ta.trend.EMAIndicator(close=data['Close'], window=10).ema_indicator()\n",
    "    data['rsi'] = ta.momentum.RSIIndicator(close=data['Close'], window=14).rsi()\n",
    "    data['macd'] = ta.trend.MACD(close=data['Close']).macd()\n",
    "    data['bb_bbm'] = ta.volatility.BollingerBands(close=data['Close']).bollinger_mavg()\n",
    "    data['day_of_week'] = data.index.dayofweek\n",
    "\n",
    "    data.dropna(inplace=True)\n",
    "    if data.empty or len(data) < seq_len:\n",
    "        print(f\"Not enough data for {ticker} after feature engineering. Skipping.\")\n",
    "        return None, None, None, None, None, None, None\n",
    "\n",
    "    feature_scaler = MinMaxScaler()\n",
    "    close_scaler = MinMaxScaler()\n",
    "    scaled_data = feature_scaler.fit_transform(data)\n",
    "    close_scaler.fit(data[['Close']])\n",
    "\n",
    "    X, y = [], []\n",
    "    for i in range(seq_len, len(scaled_data)):\n",
    "        X.append(scaled_data[i-seq_len:i])\n",
    "        y.append(scaled_data[i, data.columns.get_loc('Close')])\n",
    "\n",
    "    if not X:\n",
    "        print(f\"Not enough data to create sequences for {ticker}. Skipping.\")\n",
    "        return None, None, None, None, None, None, None\n",
    "\n",
    "    stock_ids = [stock_to_id[ticker]] * len(X)\n",
    "    \n",
    "    return np.array(X), np.array(y), np.array(stock_ids), close_scaler, currency, data, scaled_data\n",
    "\n",
    "# ===== 3. Collate Data from All Tickers =====\n",
    "all_X, all_y, all_stock_ids = [], [], []\n",
    "scalers = {}\n",
    "currencies = {}\n",
    "\n",
    "print(\"--- Starting Data Collection and Processing ---\")\n",
    "for ticker in tickers:\n",
    "    X, y, ids, scaler, currency, _, _ = process_single_ticker(ticker, start_date, end_date)\n",
    "    if X is not None:\n",
    "        all_X.append(X)\n",
    "        all_y.append(y)\n",
    "        all_stock_ids.append(ids)\n",
    "        scalers[ticker] = scaler\n",
    "        currencies[ticker] = currency\n",
    "\n",
    "X_combined = np.concatenate(all_X, axis=0)\n",
    "y_combined = np.concatenate(all_y, axis=0)\n",
    "stock_ids_combined = np.concatenate(all_stock_ids, axis=0)\n",
    "\n",
    "print(f\"\\n--- Data Processing Complete ---\")\n",
    "print(f\"Total sequences from {len(tickers)} stocks: {len(X_combined)}\")\n",
    "\n",
    "\n",
    "# ===== 4. Data Splitting & DataLoader Creation =====\n",
    "indices = np.arange(X_combined.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "X_shuffled = X_combined[indices]\n",
    "y_shuffled = y_combined[indices]\n",
    "stock_ids_shuffled = stock_ids_combined[indices]\n",
    "\n",
    "train_size = int(0.8 * len(X_shuffled))\n",
    "X_train, y_train, ids_train = X_shuffled[:train_size], y_shuffled[:train_size], stock_ids_shuffled[:train_size]\n",
    "X_test, y_test, ids_test = X_shuffled[train_size:], y_shuffled[train_size:], stock_ids_shuffled[train_size:]\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                              torch.tensor(ids_train, dtype=torch.long),\n",
    "                              torch.tensor(y_train, dtype=torch.float32))\n",
    "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32),\n",
    "                             torch.tensor(ids_test, dtype=torch.long),\n",
    "                             torch.tensor(y_test, dtype=torch.float32))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "print(f\"Data split into {len(X_train)} training and {len(X_test)} testing samples.\")\n",
    "\n",
    "\n",
    "# ===== 5. Model Definition: LSTM + Transformer with Stock Embedding =====\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "class LSTMTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, num_stocks, model_dim=64, lstm_hidden=64, n_heads=4, num_layers=2, embedding_dim=16):\n",
    "        super().__init__()\n",
    "        self.stock_embedding = nn.Embedding(num_stocks, embedding_dim)\n",
    "        self.input_proj = nn.Linear(input_dim + embedding_dim, model_dim)\n",
    "        # Using 2 layers of LSTM for more complex patterns\n",
    "        self.lstm = nn.LSTM(model_dim, lstm_hidden, batch_first=True, num_layers=2, dropout=0.1)\n",
    "        self.pos_enc = PositionalEncoding(lstm_hidden)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=lstm_hidden, nhead=n_heads, batch_first=True, activation='gelu')\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(lstm_hidden, 1)\n",
    "\n",
    "    def forward(self, x, stock_id):\n",
    "        stock_emb = self.stock_embedding(stock_id)\n",
    "        stock_emb = stock_emb.unsqueeze(1).repeat(1, x.size(1), 1)\n",
    "        x = torch.cat([x, stock_emb], dim=2)\n",
    "        x = self.input_proj(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.pos_enc(x)\n",
    "        x = self.transformer(x)\n",
    "        out = self.fc(x[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "# ===== 6. Model Training =====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "model = LSTMTransformer(\n",
    "    input_dim=X_train.shape[2],\n",
    "    num_stocks=len(tickers),\n",
    "    model_dim=128,\n",
    "    lstm_hidden=128,\n",
    "    n_heads=8,\n",
    "    num_layers=3,\n",
    "    embedding_dim=32\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "epochs = 30\n",
    "print(f\"--- Starting training for {epochs} epochs ---\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for xb, id_b, yb in train_loader:\n",
    "        xb, id_b, yb = xb.to(device), id_b.to(device), yb.to(device).unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb, id_b)\n",
    "        loss = criterion(pred, yb)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1:2d}/{epochs} | Train Loss: {avg_train_loss:.6f} | LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "print(\"--- Training Complete ---\")\n",
    "\n",
    "\n",
    "# ===== 7. Evaluation on the Entire Test Set =====\n",
    "model.eval()\n",
    "all_preds, all_actuals, all_eval_ids = [], [], []\n",
    "with torch.no_grad():\n",
    "    for xb, id_b, yb in test_loader:\n",
    "        xb, id_b = xb.to(device), id_b.to(device)\n",
    "        pred = model(xb, id_b).cpu().numpy()\n",
    "        all_preds.extend(pred.flatten())\n",
    "        all_actuals.extend(yb.numpy().flatten())\n",
    "        all_eval_ids.extend(id_b.cpu().numpy().flatten())\n",
    "\n",
    "unscaled_preds_list, unscaled_actuals_list = [], []\n",
    "for i in range(len(all_preds)):\n",
    "    stock_id = all_eval_ids[i]\n",
    "    ticker = id_to_stock[stock_id]\n",
    "    scaler = scalers.get(ticker)\n",
    "    if scaler:\n",
    "        pred_val = scaler.inverse_transform(np.array([[all_preds[i]]]))[0, 0]\n",
    "        actual_val = scaler.inverse_transform(np.array([[all_actuals[i]]]))[0, 0]\n",
    "        unscaled_preds_list.append(pred_val)\n",
    "        unscaled_actuals_list.append(actual_val)\n",
    "\n",
    "unscaled_preds = np.array(unscaled_preds_list)\n",
    "unscaled_actuals = np.array(unscaled_actuals_list)\n",
    "\n",
    "r2 = r2_score(unscaled_actuals, unscaled_preds)\n",
    "explained_variance = explained_variance_score(unscaled_actuals, unscaled_preds)\n",
    "mae = mean_absolute_error(unscaled_actuals, unscaled_preds)\n",
    "rmse = np.sqrt(mean_squared_error(unscaled_actuals, unscaled_preds))\n",
    "mape = mean_absolute_percentage_error(unscaled_actuals, unscaled_preds) * 100\n",
    "smape_numerator = np.abs(unscaled_preds - unscaled_actuals)\n",
    "smape_denominator = (np.abs(unscaled_actuals) + np.abs(unscaled_preds)) / 2\n",
    "smape_mask = smape_denominator != 0\n",
    "smape = np.mean(smape_numerator[smape_mask] / smape_denominator[smape_mask]) * 100 if np.any(smape_mask) else 0.0\n",
    "\n",
    "print(\"\\n--- Overall Model Evaluation on Test Set ---\")\n",
    "print(f\"  Goodness of Fit:\")\n",
    "print(f\"    R-squared (RÂ²):                 {r2:.4f}\")\n",
    "print(f\"    Explained Variance:             {explained_variance:.4f}\")\n",
    "print(f\"\\n  Average Error:\")\n",
    "print(f\"    Mean Absolute Error (MAE):      {mae:.4f}\")\n",
    "print(f\"    Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"    Mean Absolute % Error (MAPE):   {mape:.2f}%\")\n",
    "print(f\"    Symmetric MAPE (SMAPE):         {smape:.2f}%\")\n",
    "\n",
    "\n",
    "# ===== 8. Prediction Function for a Specific Stock =====\n",
    "def predict_next_day(ticker):\n",
    "    \"\"\"Fetches data and predicts the next day's close price for a given stock.\"\"\"\n",
    "    print(f\"\\n--- Generating Prediction for {ticker.upper()} ---\")\n",
    "    model.eval()\n",
    "\n",
    "    if ticker not in stock_to_id:\n",
    "        print(f\"Error: Model was not trained on {ticker}. Please choose from: {list(tickers)}\")\n",
    "        return\n",
    "\n",
    "    fetch_start = datetime.now() - timedelta(days=365 * 3)\n",
    "    \n",
    "    processed_data = process_single_ticker(ticker, fetch_start, datetime.now())\n",
    "    \n",
    "    if processed_data[0] is None:\n",
    "        return\n",
    "    \n",
    "    X_hist, y_hist, _, scaler, currency, data_df, full_scaled_data = processed_data\n",
    "    \n",
    "    # --- 1. Generate predictions for the historical data for plotting comparison ---\n",
    "    historical_X_tensor = torch.tensor(X_hist, dtype=torch.float32).to(device)\n",
    "    historical_id_tensor = torch.tensor([stock_to_id[ticker]] * len(X_hist), dtype=torch.long).to(device)\n",
    "    with torch.no_grad():\n",
    "        historical_preds_scaled = model(historical_X_tensor, historical_id_tensor).cpu().numpy().flatten()\n",
    "    \n",
    "    historical_preds_unscaled = scaler.inverse_transform(historical_preds_scaled.reshape(-1, 1)).flatten()\n",
    "    historical_actuals_unscaled = scaler.inverse_transform(y_hist.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # --- 2. Generate the TRUE future prediction ---\n",
    "    sequence_for_tomorrow = full_scaled_data[-seq_len:]\n",
    "    future_seq_tensor = torch.tensor([sequence_for_tomorrow], dtype=torch.float32).to(device)\n",
    "    future_id_tensor = torch.tensor([stock_to_id[ticker]], dtype=torch.long).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        future_pred_scaled = model(future_seq_tensor, future_id_tensor).cpu().numpy()[0, 0]\n",
    "\n",
    "    predicted_price_tomorrow = scaler.inverse_transform(np.array([[future_pred_scaled]]))[0, 0]\n",
    "    last_actual_price = historical_actuals_unscaled[-1]\n",
    "    \n",
    "    print(f\"Last Actual Close Price: {currency}{last_actual_price:.2f}\")\n",
    "    print(f\"Predicted Next Day's Close Price: {currency}{predicted_price_tomorrow:.2f}\")\n",
    "\n",
    "    # --- 3. Plotting ---\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    \n",
    "    date_range = data_df.index[seq_len:]\n",
    "\n",
    "    plt.plot(date_range, historical_actuals_unscaled, label='Actual Prices', color='dodgerblue', linewidth=2)\n",
    "    plt.plot(date_range, historical_preds_unscaled, label='Predicted Prices (Historical)', color='darkorange', linestyle='--', linewidth=1.5)\n",
    "    \n",
    "    future_date = date_range[-1] + timedelta(days=1)\n",
    "    plt.plot(future_date, predicted_price_tomorrow, 'go', markersize=12, label=f'Predicted Next Close ({predicted_price_tomorrow:.2f})', zorder=5)\n",
    "    \n",
    "    plt.title(f\"{ticker.upper()} Price: 3-Year Historical Comparison & Next Day Prediction (LSTM-Transformer)\", fontsize=16)\n",
    "    plt.xlabel(\"Date\", fontsize=12)\n",
    "    plt.ylabel(f\"Price ({currency})\", fontsize=12)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ===== 9. Generate Predictions for All Trained Stocks =====\n",
    "print(\"\\n--- Generating predictions for all trained stocks ---\")\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        predict_next_day(ticker)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while predicting for {ticker}: {e}\")\n",
    "\n",
    "print(\"\\n--- All predictions complete. ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
